{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import nltk\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>CAPTIONS</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>a street view looking at the culture center.</td>\n",
       "      <td>MÉCA Cultural Center / BIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>a street view looking at a white building with...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>a white folded building with urban platform go...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>urban platform goes through the middle of a wh...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>a building with white stone panel and a big en...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id     image_id  \\\n",
       "0           0   1  image_1.jpg   \n",
       "1           1   2  image_1.jpg   \n",
       "2           2   3  image_1.jpg   \n",
       "3           3   4  image_1.jpg   \n",
       "4           4   5  image_1.jpg   \n",
       "\n",
       "                                            CAPTIONS  \\\n",
       "0       a street view looking at the culture center.   \n",
       "1  a street view looking at a white building with...   \n",
       "2  a white folded building with urban platform go...   \n",
       "3  urban platform goes through the middle of a wh...   \n",
       "4  a building with white stone panel and a big en...   \n",
       "\n",
       "                   Unnamed: 3  \n",
       "0  MÉCA Cultural Center / BIG  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = pd.read_excel('captions.xlsx')\n",
    "captions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miscc.config import cfg, cfg_from_file\n",
    "from datasets import TextDataset\n",
    "from trainer import condGANTrainer as trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "miscc/config.py:103: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "cfg_from_file('cfg/coco_attn2.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.GPU_ID = 0\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "torch.manual_seed(100)\n",
    "if cfg.CUDA:\n",
    "    torch.cuda.manual_seed_all(100)\n",
    "\n",
    "now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "output_dir = '../output/%s_%s_%s' % (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp)\n",
    "\n",
    "split_dir, bshuffle = 'images', True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py2/lib/python2.7/site-packages/torchvision/transforms/transforms.py:220: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    }
   ],
   "source": [
    "imsize = cfg.TREE.BASE_SIZE * (2 ** (cfg.TREE.BRANCH_NUM - 1))\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Scale(int(imsize * 76 / 64)),\n",
    "    transforms.RandomCrop(imsize),\n",
    "    transforms.RandomHorizontalFlip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import defaultdict\n",
    "from miscc.config import cfg\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy.random as random\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(data.Dataset):\n",
    "    def __init__(self, data_dir, split='train',\n",
    "                 base_size=64,\n",
    "                 transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.norm = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        self.target_transform = target_transform\n",
    "        self.embeddings_num = cfg.TEXT.CAPTIONS_PER_IMAGE\n",
    "\n",
    "        self.imsize = []\n",
    "        for i in range(cfg.TREE.BRANCH_NUM):\n",
    "            self.imsize.append(base_size)\n",
    "            base_size = base_size * 2\n",
    "\n",
    "        self.data = []\n",
    "        self.data_dir = data_dir\n",
    "        if data_dir.find('birds') != -1:\n",
    "            self.bbox = self.load_bbox()\n",
    "        else:\n",
    "            self.bbox = None\n",
    "        split_dir = os.path.join(data_dir, split)\n",
    "\n",
    "        self.filenames, self.captions, self.ixtoword, \\\n",
    "            self.wordtoix, self.n_words = self.load_text_data(data_dir, split)\n",
    "\n",
    "        self.class_id = self.load_class_id(split_dir, len(self.filenames))\n",
    "        self.number_example = len(self.filenames)\n",
    "\n",
    "    def load_bbox(self):\n",
    "        data_dir = self.data_dir\n",
    "        bbox_path = os.path.join(data_dir, 'CUB_200_2011/bounding_boxes.txt')\n",
    "        df_bounding_boxes = pd.read_csv(bbox_path,\n",
    "                                        delim_whitespace=True,\n",
    "                                        header=None).astype(int)\n",
    "        #\n",
    "        filepath = os.path.join(data_dir, 'CUB_200_2011/images.txt')\n",
    "        df_filenames = \\\n",
    "            pd.read_csv(filepath, delim_whitespace=True, header=None)\n",
    "        filenames = df_filenames[1].tolist()\n",
    "        print('Total filenames: ', len(filenames), filenames[0])\n",
    "        #\n",
    "        filename_bbox = {img_file[:-4]: [] for img_file in filenames}\n",
    "        numImgs = len(filenames)\n",
    "        for i in xrange(0, numImgs):\n",
    "            # bbox = [x-left, y-top, width, height]\n",
    "            bbox = df_bounding_boxes.iloc[i][1:].tolist()\n",
    "\n",
    "            key = filenames[i][:-4]\n",
    "            filename_bbox[key] = bbox\n",
    "        #\n",
    "        return filename_bbox\n",
    "\n",
    "    def load_captions(self, data_dir, filenames):\n",
    "        all_captions = []\n",
    "        for i in range(len(filenames)):\n",
    "            cap_path = '%s/text/%s.txt' % (data_dir, filenames[i])\n",
    "            with open(cap_path, \"r\") as f:\n",
    "                captions = f.read().decode('utf8').split('\\n')\n",
    "                cnt = 0\n",
    "                for cap in captions:\n",
    "                    if len(cap) == 0:\n",
    "                        continue\n",
    "                    cap = cap.replace(\"\\ufffd\\ufffd\", \" \")\n",
    "                    # picks out sequences of alphanumeric characters as tokens\n",
    "                    # and drops everything else\n",
    "                    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "                    tokens = tokenizer.tokenize(cap.lower())\n",
    "                    # print('tokens', tokens)\n",
    "                    if len(tokens) == 0:\n",
    "                        print('cap', cap)\n",
    "                        continue\n",
    "\n",
    "                    tokens_new = []\n",
    "                    for t in tokens:\n",
    "                        t = t.encode('ascii', 'ignore').decode('ascii')\n",
    "                        if len(t) > 0:\n",
    "                            tokens_new.append(t)\n",
    "                    all_captions.append(tokens_new)\n",
    "                    cnt += 1\n",
    "                    if cnt == self.embeddings_num:\n",
    "                        break\n",
    "                if cnt < self.embeddings_num:\n",
    "                    print('ERROR: the captions for %s less than %d'\n",
    "                          % (filenames[i], cnt))\n",
    "        return all_captions\n",
    "\n",
    "    def build_dictionary(self, train_captions, test_captions):\n",
    "        word_counts = defaultdict(float)\n",
    "        captions = train_captions + test_captions\n",
    "        for sent in captions:\n",
    "            for word in sent:\n",
    "                word_counts[word] += 1\n",
    "\n",
    "        vocab = [w for w in word_counts if word_counts[w] >= 0]\n",
    "\n",
    "        ixtoword = {}\n",
    "        ixtoword[0] = '<end>'\n",
    "        wordtoix = {}\n",
    "        wordtoix['<end>'] = 0\n",
    "        ix = 1\n",
    "        for w in vocab:\n",
    "            wordtoix[w] = ix\n",
    "            ixtoword[ix] = w\n",
    "            ix += 1\n",
    "\n",
    "        train_captions_new = []\n",
    "        for t in train_captions:\n",
    "            rev = []\n",
    "            for w in t:\n",
    "                if w in wordtoix:\n",
    "                    rev.append(wordtoix[w])\n",
    "            # rev.append(0)  # do not need '<end>' token\n",
    "            train_captions_new.append(rev)\n",
    "\n",
    "        test_captions_new = []\n",
    "        for t in test_captions:\n",
    "            rev = []\n",
    "            for w in t:\n",
    "                if w in wordtoix:\n",
    "                    rev.append(wordtoix[w])\n",
    "            # rev.append(0)  # do not need '<end>' token\n",
    "            test_captions_new.append(rev)\n",
    "\n",
    "        return [train_captions_new, test_captions_new,\n",
    "                ixtoword, wordtoix, len(ixtoword)]\n",
    "\n",
    "    def load_text_data(self, data_dir, split):\n",
    "        filepath = os.path.join(data_dir, 'captions.pickle')\n",
    "        train_names = self.load_filenames(data_dir, 'train')\n",
    "        test_names = self.load_filenames(data_dir, 'test')\n",
    "        if not os.path.isfile(filepath):\n",
    "            train_captions = self.load_captions(data_dir, train_names)\n",
    "            test_captions = self.load_captions(data_dir, test_names)\n",
    "\n",
    "            train_captions, test_captions, ixtoword, wordtoix, n_words = \\\n",
    "                self.build_dictionary(train_captions, test_captions)\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump([train_captions, test_captions,\n",
    "                             ixtoword, wordtoix], f, protocol=2)\n",
    "                print('Save to: ', filepath)\n",
    "        else:\n",
    "            with open(filepath, 'rb') as f:\n",
    "                x = pickle.load(f)\n",
    "                train_captions, test_captions = x[0], x[1]\n",
    "                ixtoword, wordtoix = x[2], x[3]\n",
    "                del x\n",
    "                n_words = len(ixtoword)\n",
    "                print('Load from: ', filepath)\n",
    "        if split == 'train':\n",
    "            # a list of list: each list contains\n",
    "            # the indices of words in a sentence\n",
    "            captions = train_captions\n",
    "            filenames = train_names\n",
    "        else:  # split=='test'\n",
    "            captions = test_captions\n",
    "            filenames = test_names\n",
    "        return filenames, captions, ixtoword, wordtoix, n_words\n",
    "\n",
    "    def load_class_id(self, data_dir, total_num):\n",
    "        if os.path.isfile(data_dir + '/class_info.pickle'):\n",
    "            with open(data_dir + '/class_info.pickle', 'rb') as f:\n",
    "                class_id = pickle.load(f)\n",
    "        else:\n",
    "            class_id = np.arange(total_num)\n",
    "        return class_id\n",
    "\n",
    "    def load_filenames(self, data_dir, split):\n",
    "        filepath = '%s/%s/filenames.pickle' % (data_dir, split)\n",
    "        if os.path.isfile(filepath):\n",
    "            with open(filepath, 'rb') as f:\n",
    "                filenames = pickle.load(f)\n",
    "            print('Load filenames from: %s (%d)' % (filepath, len(filenames)))\n",
    "        else:\n",
    "            filenames = []\n",
    "        return filenames\n",
    "\n",
    "    def get_caption(self, sent_ix):\n",
    "        # a list of indices for a sentence\n",
    "        sent_caption = np.asarray(self.captions[sent_ix]).astype('int64')\n",
    "        if (sent_caption == 0).sum() > 0:\n",
    "            print('ERROR: do not need END (0) token', sent_caption)\n",
    "        num_words = len(sent_caption)\n",
    "        # pad with 0s (i.e., '<end>')\n",
    "        x = np.zeros((cfg.TEXT.WORDS_NUM, 1), dtype='int64')\n",
    "        x_len = num_words\n",
    "        if num_words <= cfg.TEXT.WORDS_NUM:\n",
    "            x[:num_words, 0] = sent_caption\n",
    "        else:\n",
    "            ix = list(np.arange(num_words))  # 1, 2, 3,..., maxNum\n",
    "            np.random.shuffle(ix)\n",
    "            ix = ix[:cfg.TEXT.WORDS_NUM]\n",
    "            ix = np.sort(ix)\n",
    "            x[:, 0] = sent_caption[ix]\n",
    "            x_len = cfg.TEXT.WORDS_NUM\n",
    "        return x, x_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #\n",
    "        key = self.filenames[index]\n",
    "        cls_id = self.class_id[index]\n",
    "        #\n",
    "        if self.bbox is not None:\n",
    "            bbox = self.bbox[key]\n",
    "            data_dir = '%s/CUB_200_2011' % self.data_dir\n",
    "        else:\n",
    "            bbox = None\n",
    "            data_dir = self.data_dir\n",
    "        #\n",
    "        img_name = '%s/images/%s.jpg' % (data_dir, key)\n",
    "        imgs = get_imgs(img_name, self.imsize,\n",
    "                        bbox, self.transform, normalize=self.norm)\n",
    "        # random select a sentence\n",
    "        sent_ix = random.randint(0, self.embeddings_num)\n",
    "        new_sent_ix = index * self.embeddings_num + sent_ix\n",
    "        caps, cap_len = self.get_caption(new_sent_ix)\n",
    "        return imgs, caps, cap_len, cls_id, key\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load filenames from: ../coco1/train/filenames.pickle (82783)\n",
      "Load filenames from: ../coco1/test/filenames.pickle (40470)\n",
      "Load from:  ../coco1/captions.pickle\n"
     ]
    }
   ],
   "source": [
    "dataset = TextDataset(cfg.DATA_DIR, split_dir,\n",
    "                          base_size=cfg.TREE.BASE_SIZE,\n",
    "                          transform=image_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('wordtoix.npy',dataset.wordtoix)\n",
    "np.save('ixtoword.npy',dataset.ixtoword)\n",
    "\n",
    "with open('wordtoix.pickle', 'wb') as handle:\n",
    "    pickle.dump(dataset.wordtoix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('ixtoword.pickle', 'wb') as handle:\n",
    "    pickle.dump(dataset.ixtoword, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=cfg.TRAIN.BATCH_SIZE,\n",
    "        drop_last=True, shuffle=bshuffle, num_workers=int(cfg.WORKERS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = trainer(output_dir, dataloader, dataset.n_words, dataset.ixtoword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40470, 202350)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.filenames), len(dataset.captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202350"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40470*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
